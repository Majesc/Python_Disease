Wprowadzenie -m
Celem projektu byo stworzenie modelu klasyfikacyjnego, kt贸ry przewiduje diagnoz chor贸b na podstawie symptom贸w. Zastosowano podejcie uczenia maszynowego, wykorzystujc r贸偶ne modele klasyfikacyjne, takie jak Random Forest, Support Vector Machine (SVM) oraz Gradient Boosting. Projekt obejmowa tak偶e przetwarzanie danych, w tym normalizacj tekstu, usuwanie zbdnych cech, a tak偶e wizualizacj zale偶noci midzy symptomami a chorobami.

1锔 Importowanie bibliotek
Zaimportowano niezbdne biblioteki do analizy danych (pandas, numpy), wizualizacji (matplotlib, seaborn), przetwarzania jzyka naturalnego (nltk), oraz uczenia maszynowego (sklearn). Wykorzystane zasoby jak stopwords i wordnet z NLTK umo偶liwiaj obr贸bk tekstu, a narzdzia z sklearn su偶 do tworzenia modeli klasyfikacyjnych i oceny wynik贸w.

2锔 Wczytanie danych
Funkcja wczytuje dane z plik贸w CSV, usuwa zbdn kolumn "Unnamed: 133" oraz kolumn "fluid_overload", jeli wystpuje. Oczyszczone dane s zwracane jako dwa DataFrame: train_df i test_df.

3锔 Normalizacja tekstu
Funkcja przetwarza tekst, wykonujc nastpujce kroki:

Zamiana na mae litery i usunicie zbdnych spacji.
Usunicie znak贸w specjalnych i cyfr.
Usunicie stop words (czsto wystpujcych, ale mao znaczcych s贸w).
Lematyzacja s贸w do ich podstawowej formy.
Usunicie duplikat贸w s贸w.
Na koniec tekst jest formatowany, tak aby ka偶de sowo zaczynao si wielk liter.

4锔 Przetwarzanie danych
Funkcja przeprowadza kilka operacji na danych:

Normalizacja tekstu w kolumnie 'prognosis' dla obu zbior贸w (treningowego i testowego).
Podzia danych na cechy (X) i etykiety (y), gdzie etykiety to kolumna 'prognosis'.
Kodowanie etykiet za pomoc LabelEncoder.
Skalowanie cech przy u偶yciu StandardScaler.
Podzia danych na zbi贸r treningowy i walidacyjny.
Funkcja zwraca przetworzone dane oraz obiekty przydatne do dalszego modelowania (label_encoder, scaler).

5锔 Macierz korelacji
Funkcja tworzy macierz korelacji midzy cechami w zbiorze danych:

Kodowanie celu: Tymczasowo koduje etykiety w kolumnie 'prognosis' za pomoc LabelEncoder.
Obliczenie korelacji: Oblicza korelacje midzy wszystkimi cechami za pomoc metody .corr().
Wizualizacja: Tworzy wykres ciepa (heatmap) z u偶yciem biblioteki seaborn dla macierzy korelacji, z odpowiedni kolorystyk i etykietami.
Funkcja umo偶liwia wizualn analiz zale偶noci midzy cechami, co mo偶e pom贸c w zrozumieniu struktury danych.

6锔 Gstociowa mapa cieplna (symptomy vs choroby)
Funkcja tworzy map ciepln ilustrujc zale偶no midzy symptomami a chorobami:

Obliczanie rednich symptom贸w: Oblicza rednie wystpienie symptom贸w dla ka偶dej choroby w zbiorze danych.
Normalizacja: Normalizuje rednie wartoci symptom贸w, dzielc przez redni warto symptom贸w w caym zbiorze.
Wizualizacja: Rysuje map ciepln, gdzie kolory reprezentuj znormalizowane wartoci wystpowania symptom贸w w r贸偶nych chorobach.
Mapa cieplna pomaga w analizie, kt贸re symptomy s istotne dla poszczeg贸lnych chor贸b.

7锔 Trenowanie modelu
Funkcja su偶y do trenowania modelu klasyfikacyjnego:

Wyb贸r modelu: Funkcja umo偶liwia wyb贸r spor贸d trzech modeli: RandomForestClassifier, SVC (Support Vector Machine) oraz GradientBoostingClassifier.
Hiperparametry: Dla ka偶dego modelu definiowana jest siatka hiperparametr贸w do optymalizacji.
Optymalizacja: Zastosowanie GridSearchCV do przeszukiwania najlepszych hiperparametr贸w za pomoc walidacji krzy偶owej (cross-validation).
Zwr贸cenie najlepszego modelu: Po przeprowadzeniu przeszukiwania, funkcja zwraca najlepszy model.

8锔 Ocena modelu
Funkcja ocenia wydajno modelu:

Predykcja: Przewiduje etykiety dla danych walidacyjnych.
Dokadno: Oblicza dokadno modelu na podstawie por贸wnania przewidywanych i rzeczywistych etykiet.
Raport klasyfikacji: Wywietla raport z miarami jakoci klasyfikacji, takimi jak precyzja, recall, F1-score.
Macierz konfuzji: Rysuje map ciepln macierzy konfuzji, pokazujc bdy modelu w przewidywaniach.

9锔 Testowanie na zbiorze testowym
Funkcja testuje model na nowych, nieznanych danych:

Przygotowanie danych: Usuwa kolumn 'prognosis' z danych testowych i koduje etykiety za pomoc wczeniej nauczonego label_encoder.
Skalowanie cech: Zastosowanie wczeniej wytrenowanego skalera do przeksztacenia cech.
Predykcja: Model przewiduje etykiety na podstawie danych testowych.
Ocena: Oblicza dokadno modelu na zbiorze testowym.
Funkcja zwraca dokadno modelu na danych testowych.

 Testy jednostkowe
W tej czci projektu zastosowano testy jednostkowe:

setUp: Przygotowanie danych, przetwarzanie i trenowanie modelu przed ka偶dym testem.
Testy:
test_model_training: Sprawdza, czy model zosta poprawnie wytrenowany (nie jest None).
test_prediction_shape: Weryfikuje, czy liczba predykcji zgadza si z liczb pr贸bek w zbiorze walidacyjnym.
test_accuracy_threshold: Sprawdza, czy dokadno modelu na zbiorze testowym przekracza 70%.
Testy jednostkowe pomagaj upewni si, 偶e proces trenowania, predykcji i oceny modelu dziaa zgodnie z oczekiwaniami.

 Wykonanie kodu
Oto peny przepyw pracy w projekcie:

Wczytanie danych: Zaadowanie danych treningowych i testowych.
Przetwarzanie danych: Usunicie zbdnych kolumn, przetworzenie danych oraz podzia na zbiory treningowe, walidacyjne i testowe.
Wizualizacje: Utworzenie wykres贸w przedstawiajcych macierz korelacji oraz map ciepln symptom贸w vs choroby.
Trenowanie modelu: Wybranie modelu i jego trenowanie na danych treningowych.
Ocena modelu: Ocena wynik贸w modelu na zbiorze walidacyjnym oraz wizualizacja wynik贸w.
Testowanie modelu: Testowanie modelu na zbiorze testowym i sprawdzenie dokadnoci.
Cay proces przechodzi przez etapy od wczytania danych po finaln ocen modelu, co zapewnia pen ocen jego efektywnoci.

Analiza wynik贸w
Po przeprowadzeniu procesu trenowania i oceny modelu, uzyskano dokadno na poziomie powy偶ej 70% dla zbioru testowego, co jest wynikiem zadowalajcym w kontekcie problemu klasyfikacyjnego. Model zosta oceniony pod ktem dokadnoci, precyzji, recall i F1-score, co pozwolio na dokadn analiz jego wydajnoci w r贸偶nych klasach. Zastosowanie macierzy korelacji i mapy cieplnej umo偶liwio wizualizacj zale偶noci midzy symptomami a chorobami, co pozwolio lepiej zrozumie, kt贸re cechy s istotne.

Wnioski kocowe
Model Random Forest okaza si najbardziej efektywny w kontekcie tego zadania, osigajc najlepsze wyniki. Optymalizacja hiperparametr贸w przyczynia si do poprawy wynik贸w klasyfikacji.
Przetwarzanie danych miao kluczowe znaczenie dla jakoci modelu. Usunicie zbdnych cech, normalizacja tekstu i skalowanie danych pozytywnie wpyny na efektywno modelu.
Wizualizacje dostarczyy cennych informacji o zale偶nociach midzy symptomami a diagnozami, co mo偶e pom贸c w dalszym udoskonalaniu modelu.
Projekt wykaza, 偶e odpowiednie przetwarzanie danych oraz wyb贸r odpowiednich modeli klasyfikacyjnych mog prowadzi do skutecznych predykcji, przy czym dalsza optymalizacja i testowanie nowych podej mo偶e poprawi wyniki.
